{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_height</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>jellybeanpie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPT: If you really want to connect with someon...</td>\n",
       "      <td>17851</td>\n",
       "      <td>https://www.reddit.com/r/LifeProTips/comments/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>TheFirstMultimate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seeing a [deleted] comment is like arriving la...</td>\n",
       "      <td>27056</td>\n",
       "      <td>https://www.reddit.com/r/Showerthoughts/commen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Figsnbacon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Heartbroken she couldn’t win the TRex in the c...</td>\n",
       "      <td>15606</td>\n",
       "      <td>https://i.redd.it/rewlox8jm2011.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>jessejamess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Double Cork Dome Drag</td>\n",
       "      <td>12815</td>\n",
       "      <td>https://gfycat.com/ForsakenMediumClownanemonefish</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>waterunderwind</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>TIL: albino sequoias, A tree that can’t produc...</td>\n",
       "      <td>1877</td>\n",
       "      <td>https://ascendenza.files.wordpress.com/2011/02...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>promo_adult</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  approved_at_utc  approved_by  archived             author  \\\n",
       "0           0              NaN          NaN     False       jellybeanpie   \n",
       "1           1              NaN          NaN     False  TheFirstMultimate   \n",
       "2           2              NaN          NaN     False         Figsnbacon   \n",
       "3           3              NaN          NaN     False        jessejamess   \n",
       "4           4              NaN          NaN     False     waterunderwind   \n",
       "\n",
       "   author_cakeday  author_flair_css_class  author_flair_template_id  \\\n",
       "0             NaN                     NaN                       NaN   \n",
       "1             NaN                     NaN                       NaN   \n",
       "2             NaN                     NaN                       NaN   \n",
       "3             NaN                     NaN                       NaN   \n",
       "4             1.0                     NaN                       NaN   \n",
       "\n",
       "   author_flair_text  banned_at_utc ...   thumbnail_height  thumbnail_width  \\\n",
       "0                NaN            NaN ...                NaN              NaN   \n",
       "1                NaN            NaN ...                NaN              NaN   \n",
       "2                NaN            NaN ...              140.0            140.0   \n",
       "3                NaN            NaN ...               78.0            140.0   \n",
       "4                NaN            NaN ...              140.0            140.0   \n",
       "\n",
       "                                               title    ups  \\\n",
       "0  LPT: If you really want to connect with someon...  17851   \n",
       "1  Seeing a [deleted] comment is like arriving la...  27056   \n",
       "2  Heartbroken she couldn’t win the TRex in the c...  15606   \n",
       "3                              Double Cork Dome Drag  12815   \n",
       "4  TIL: albino sequoias, A tree that can’t produc...   1877   \n",
       "\n",
       "                                                 url  user_reports  \\\n",
       "0  https://www.reddit.com/r/LifeProTips/comments/...            []   \n",
       "1  https://www.reddit.com/r/Showerthoughts/commen...            []   \n",
       "2                https://i.redd.it/rewlox8jm2011.jpg            []   \n",
       "3  https://gfycat.com/ForsakenMediumClownanemonefish            []   \n",
       "4  https://ascendenza.files.wordpress.com/2011/02...            []   \n",
       "\n",
       "   view_count visited whitelist_status  wls  \n",
       "0         NaN   False          all_ads  6.0  \n",
       "1         NaN   False          all_ads  6.0  \n",
       "2         NaN   False          all_ads  6.0  \n",
       "3         NaN   False          all_ads  6.0  \n",
       "4         NaN   False      promo_adult  1.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data')\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22580, 85)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting binary variable: low vs high comments\n",
    "    #low defined as <= median number of comments/post: <= 12\n",
    "    #high defined as > median number of comments/post: > 12\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "median_comments = np.median(data['num_comments'])\n",
    "median_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    11593\n",
       "True     10987\n",
       "Name: binary_comments, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add in binary label as target in dataset\n",
    "data['binary_comments'] = [False if i <= 12 else True for i in data['num_comments']]\n",
    "data['binary_comments'].head()\n",
    "\n",
    "#check values\n",
    "    #51% of posts labeled low: False (inclusive of 12)\n",
    "    #49% of posts labeled high: True (exclusive of 12)\n",
    "data['binary_comments'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelen/anaconda3/envs/dsi/lib/python3.6/site-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  box_data = remove_na(group_data)\n"
     ]
    }
   ],
   "source": [
    "#Plot distribution of num_comments/post\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "plt.hist(data['num_comments']);\n",
    "\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "sns.boxplot(data['num_comments']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4865810451727192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline accuracy for model is % of high comments\n",
    "baseline = data['binary_comments'].value_counts()[1] / (len(data['binary_comments']))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelen/anaconda3/envs/dsi/lib/python3.6/site-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  box_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "funny                   89\n",
       "aww                     81\n",
       "gaming                  66\n",
       "pics                    63\n",
       "memes                   62\n",
       "FortNiteBR              61\n",
       "PrequelMemes            58\n",
       "gifs                    55\n",
       "PewdiepieSubmissions    55\n",
       "LiverpoolFC             51\n",
       "Showerthoughts          50\n",
       "rupaulsdragrace         50\n",
       "mildlyinteresting       50\n",
       "todayilearned           47\n",
       "DDLC                    46\n",
       "DeepFriedMemes          45\n",
       "oddlysatisfying         44\n",
       "LivestreamFail          43\n",
       "greatawakening          43\n",
       "tumblr                  42\n",
       "AskReddit               42\n",
       "MemeEconomy             41\n",
       "BlackPeopleTwitter      40\n",
       "FireEmblemHeroes        40\n",
       "wholesomememes          39\n",
       "CringeAnarchy           39\n",
       "greentext               37\n",
       "OldSchoolCool           37\n",
       "StarWars                36\n",
       "cursedimages            36\n",
       "                        ..\n",
       "badphilosophy            1\n",
       "Spongebros               1\n",
       "TooGoodOfADesign         1\n",
       "robotics                 1\n",
       "UnexpectedDDLC           1\n",
       "ClassicalMemes           1\n",
       "LilyCollins              1\n",
       "MotoUK                   1\n",
       "Dogberg                  1\n",
       "ProgrammerDadJokes       1\n",
       "QUALITYanime             1\n",
       "IsabelaFernandez         1\n",
       "Artifact                 1\n",
       "Panda_Gifs               1\n",
       "ICanDrawThat             1\n",
       "52book                   1\n",
       "AnnArbor                 1\n",
       "wec                      1\n",
       "FolkPunk                 1\n",
       "lele_pons                1\n",
       "Brooklyn                 1\n",
       "fullmoviesongoogle       1\n",
       "Botchedsurgeries         1\n",
       "VXJunkies                1\n",
       "Petscop                  1\n",
       "sphynx                   1\n",
       "microsoft                1\n",
       "rarekumikos              1\n",
       "PSP                      1\n",
       "ENFP                     1\n",
       "Name: subreddit, Length: 3736, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAFUCAYAAAA+k2k3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEKtJREFUeJzt3X+MZWV9x/H33R0WZ9aBjDr+jD+aGp8BmwjFDRsUllLdFmKdlE1JW6D+qKYxVG1j0GCwAWr9AwyNpBJ/1dJWW0pFssZA3VotxVoQFSJ0d74KteKPNBmXWVl2Vtxdpn/cO9txe2bmPss598x95v36h++9d+4935DNJ895znPO01lYWECS+rWh7QYkDRdDQ1IWQ0NSFkNDUhZDQ1IWQ0NSlpG2G1jJ7Ox+rwdLLZmcHO9Uve9IQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ42YmdnNzMzutttQA9b0MnINr507bwVgaurUljtR3RxpqHYzM7uJ2EPEHkcbBTI0VLvFUcaxtcpgaEjKYmiodtPTOyprlcGJUNVuaupUUjrlaK2yGBpqhCOMcnXW8mZJPrlLao9P7pJUC0NDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0ONcFvGcvlgYTXCbRnL5UhDtXNbxrIZGqqd2zKWzdCQlKWxOY2U0gnAXwMvAY4AbwUOAzcBC8CDwGUR8WRTPagd09M7uPba9x+tVZYmRxoXACMRcRZwDfBnwPXAlRFxNtABphs8vlqyuC1jSqc4EVqgJq+efBsYSSltAE4CDgFbgTt7n98BbAdua7AHtcQRRrmaDI3H6Z6azADPAl4HnBMRi1st7gdOXukHJibGGBnZ2GCLasrk5Jltt6CGNBkafwx8ISKuSCm9EPgSsGnJ5+PAvpV+YG5uvsH2JK1kcnK88v0m5zTmgJ/06keBE4D7Ukrn9t47H7irweNLakBju8anlJ4OfBJ4Ht0RxoeArwMf773eA7w1Io4s9xvuGi+1Z7ld4xsLjToYGlJ7lgsNF3dJymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaEjKYmhIymJoSMpiaKgRMzO7mZnZ3XYbasBI2w2oTDt33grA1NSpLXeiujnSUO1mZnYTsYeIPY42CmRoqHaLo4xja5XB0JCUxdBQ7aand1TWKoMToard1NSppHTK0VplMTTUCEcY5eosLCy03cOyZmf3r93mpMJNTo53qt53TkNSFkNDjXBFaLmc01AjXBFaLkcaqp0rQstmaKh2rggtm6EhKYuhodqdfvoZlbXKYGiodvfd943KWmUwNCRlMTRUO29YK5uhISmLoaHaecm1bI2uCE0pXQG8HtgE3AjcCdwELAAPApdFxJNN9iCpXo2NNFJK5wJnAa8CtgEvBK4HroyIs4EOMN3U8dUe5zTK1uRI49eAB4DbgJOAy4G30h1tANwBbO99roL4EJ6yNRkazwJeDLwO+AXgc8CGiFh8RsZ+4OSVfmBiYoyRkY0NtqimvOENlwIwOTnecieqW5OhsReYiYifAZFS+indU5RF48C+lX5gbm6+wfbUpOc+9yUAzM7ub7cRHbflAr/JqydfAX49pdRJKT0f2Az8S2+uA+B84K4Gjy+pAY2NNCLi8ymlc4Cv0Q2ny4DvAh9PKW0C9gCfaer4atfiLfHOaZSn0UuuEfHuire3NXlMrQ0+hKdcLu5S7XwIT9kMDdXOFaFlMzQkZTE0VDtXhJbNp5Grdq4ILZuhoUY4wiiX2zJKquS2jJJqYWioEbt23c6uXbe33YYa4JyGGrFz52cB2L79gpY7Ud0caah2u3bdzsGD8xw8OO9oo0CGhmq3OMo4tlYZDA1JWQwN1W56+sLKWmUwNFS77dsvYHR0jNHRMSdCC+TVEzXCEUa5XBEqqZIrQiXVwtCQlMXQkJTF0JCUxdCQlMXQUCNmZnb7JPJCuU5DjXDfk3I50lDt3PekbKuGRkrp5RXvbW2mHZXAfU/KtuzpSUrpVcBG4BMppd8HOku+8xHgZc23J2mtWWlO47V09119HnDNkvcPAx9tsikNt9HR0cpaZVg2NCLiKoCU0qUR8bcD60hD71vfur+yVhlWOj25qhcc56WUfuXYzyPizU02JmltWun05Bu9//7rAPpQQbZtO48vf/mLR2uVZdlb41NKL1rpixHxSCMdLeGt8cPrLW+5BIBPfOJTLXei47XcrfErjTTuBBaApwHPAf4LOAK8FHgImKq5RxXEEUa5Vn0IT0rpZuDDEXFX7/UW4N0R8VtNN+dIQ2rPU3kIzymLgQEQEffiKENat/q59+QHKaVrgH+gu8DrUuDbjXalobe4fNx7T8rTT2hcQndx18105zi+CLyxwZ5UAG9YK9eqoRERc8DbB9CLCrF4w9pibXCUZaXFXU/SHVksOkT36snTgMciYqLh3jSkjr1hzdAoy7IToRGxISI2Ah8D3gCMRsRm4CLgMwPqT9Ia08/VkzMj4lMRsQAQEbcCr2y2LQ2z008/o7JWGfqZCD2QUnoTcAvdkLkUeLTRrjTU7rvvGz9XuzVjWfoZaVwCXAj8D/AD4FfpBoekdWjV0IiI70XEbwAvjoiTI2JHRPxoAL1pSE1P76isVYZVT09SSqfRXaMx1nvM378BF0XEN5tuTtLa08/pyQ3AbwJ7eyOMt9F93J9UyWeElq2f0BiLxZU6QET8M3Bicy1JWsv6CY1HU0qvoLfQK6V0MV490Qq85Fq2fkLjbcCHgZenlPYBfwT8QaNdaagde8lVZelnncZrIuLVKaXNwMaIeKzppiStXf2MNN4OEBEHDAz14/nPf0FlrTL0M9L4fkrpS8A9wMHFNyPimuW/ovXs7ru/+nP1pZf64PqS9BMady+pKx//JWn96Od5GlenlE6g+4i/Q8B3IuJI451paE1PX8jNN3/qaK2y9LMB9Dl0n0T+V8DfAzMpJe9yldapfiZC/xy4ICJeGRGnA78D3NhsWxpmO3d+trJWGfoJjU5EPLD4IiK+Tn9zIZIKtNLj/s7plXtSSh8B/pLujvEXA18bQG8aUlu3nnV0W8atW89quRvVbaURw9XHvL52Se0mRlrWj370w8paZVg2NCLi/+0UL0n9PE/jy1SMLCJi1c06U0rPprv7/Gvpntrc1PutB4HLIuLJzH41BKand3Dtte8/Wqss/UyEXkX3VOVq4APAfwJfWe1LvbUdH+X/VpFeD1wZEWfTXSQ2fRz9agg88sh/V9YqQz+Lu+485q0vppTuAf5kla9+kO7Deq7ovT6D7k70AHcA24Hb+m9Vw+LYS64+WLgs/ZyevGjJyw7wS8AzV/nOG4HZiPhCSmkxNDqL2yAA+4GTVzv2xMQYIyMbV/szrTGdzs/Xk5Pj7TWj2vWz3uJOuvMQHeBJ4MfAH67ynTcDCyml1wCnAX8DPHvJ5+PAvtUOPDc330d7Wmte9rIp7r//m0fr2dn9LXek47Fc2Pczp/HbdB/CMwU8DPzial+IiHMiYltEnAvcD/wecEdK6dzen5wP3NXHsTWEImYqa5Whn9D4EPAA3b1P5oHTgT89jmO9C7g6pfQfwCbc2lEaSv2cnmyIiF0ppU8Dt0bE91NKfS8j7402Fm3LbVDDx7tcy9bPSGM+pfQu4Dzg8ymld9CdyJQqbd9+AaOjY4yOjnnlpED9hMbFwGZgR0TMAS8AfrfRrjT0Upoipam221AD+lmn8UPgmiWv39NoRyqCE6Dl6mekIWXZtet2Dh6c5+DBeXbtur3tdlQzQ0O18yE8ZTM0JGUxNFQ79z0pm6Gh2n33uw9X1iqDoSEpi6Gh2k1MPKOyVhkMDdVu794fV9Yqg6EhKYuhodqddtovV9Yqg6Gh2k1NnVpZqwyGhmrnitCyGRqSshgaqp0rQstmaKh2rggtm6EhKYuhodpt23ZeZa0yGBqq3SOPfK+yVhkMDdXu4Ye/U1mrDIaGpCyGhmq3cePGylplMDRUuyNHjlTWKoOhISmLoaHanXjiiZW1ymBoqHaHDh2qrFUGQ0NSFkNDtXNFaNkMDdVuy5atlbXKYGiodjt33lpZqwyGhqQshoZqd/jw4cpaZTA0VDtvWCuboSEpi6Gh2rkitGyGhmr3xBNPVNYqg6EhKYuhodq5hUHZDA3Vbt++ucpaZTA0VLv5+fnKWmUwNCRlMTQkZTE0JGUxNCRlMTRUu06nU1mrDIaGarewsFBZqwyGhqQshoZq98xnPquyVhkMDdXuscd+UlmrDIaGaue+J2UzNCRlMTQkZTE0JGUxNCRlMTQkZTE0VDuXkZfN0FDtXEZetpEmfjSldALwSeAlwInA+4HdwE3AAvAgcFlEPNnE8SU1p6mRxiXA3og4Gzgf+AvgeuDK3nsdYLqhY0tqUFOh8Y/A+5a8PgycAdzZe30H8JqGji2pQY2cnkTE4wAppXHgM8CVwAcjYvEEdz9w8mq/MzExxsjIxiZa1ABNTo633YJq1EhoAKSUXgjcBtwYEX+XUrp2ycfjwL7VfmNuzidZl2B2dn/bLeg4LBf2jZyepJSeA+wC3hMRn+y9fV9K6dxefT5wVxPHltSspkYa7wUmgPellBbnNt4J3JBS2gTsoXvaImnINDWn8U66IXGsbU0cT9LguLhLUhZDQ1IWQ0NSFkNDUpbOWr6haHZ2/9ptboBuueXT3HvvPW23kWXv3h8Dw/c08i1bzuSiiy5uu401YXJyvPIWZUcakrI40lAjLr/8HQBcd90NLXei4+VIQ1ItDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVkMDUlZDA1JWQwNSVnW5V6uH/jAVczNPdrET6tn8f/vxMQzWu6kbBMTz+C9772qkd9ebi/XkUaOtsbNzT3K3r176Zww2nYrxVroDWIffWy+5U7KtXDoYCvHXZehAdA5YZSnv/T1bbchHbfHH/pcK8d1TkNSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUhZDQ1IWQ0NSFkNDUpZ1ee/JgQMHWDj009bW7kt1WDh0kAMHBn+XuiMNSVnW5Uhj8+bNPHGk412uGmqPP/Q5Nm8eG/hxHWlIymJoSMpiaEjKYmhIyrIuJ0Khe7nKS67NWTjyMwA6Gze13Em5us8IHfxE6LoMDZ+Q3by5uZ8CMHHS4P9Rrx9jrfxbXpdbGKh5l1/+DgCuu+6GljvR8VpuCwNDYwjccsunuffee9puI8uw7nuyZcuZXHTRxW23sSasiX1PUkobgBuBVwBPAG+JiIcG2YMGY9OmE9tuQQ0Z6EgjpXQh8PqIeGNKaStwRURML/f3jjSk9iw30hj0JddXA/8EEBF3A68c8PElPUWDvnpyEvCTJa+PpJRGIuJw1R9PTIwxMrJxMJ1J6sugQ+MxYHzJ6w3LBQbA3Jz7gEptmZwcr3x/0Kcn/w5cANCb03hgwMeX9BQNeqRxG/DalNJXgQ7wpgEfX9JT5DoNSZXWytUTSUPO0JCUxdCQlMXQkJTF0JCUxdCQlMXQkJRlTa/TkLT2ONKQlMXQkJTF0JCUxdCQlMXQkJTF0JCU5X8B/KRspJADXnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set feature and target variables\n",
    "X = data['subreddit']\n",
    "y = data['binary_comments']\n",
    "\n",
    "fig = plt.figure(figsize = (4, 6))\n",
    "sns.boxplot(X.value_counts(), orient = 'v');\n",
    "\n",
    "print(type(X))\n",
    "X.value_counts()\n",
    "#data[data['subreddit'] == 'funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_X: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "cv_X_array: <class 'numpy.ndarray'>\n",
      "(22580, 3734) (22580,)\n"
     ]
    }
   ],
   "source": [
    "#additional step: group similar subreddits\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#X_lemma = [lemmatizer.lemmatize(i) for i in X]\n",
    "#for i in X:\n",
    "#    print (i, lemmatizer.lemmatize(i))\n",
    "\n",
    "#CountVectorize feature set\n",
    "cv = CountVectorizer(stop_words = 'english')\n",
    "cv.fit(X)\n",
    "cv_X = cv.fit_transform(X)\n",
    "cv_X_array = cv_X.toarray()\n",
    "\n",
    "print('cv_X:', type(cv_X))\n",
    "print('cv_X_array:', type(cv_X_array))\n",
    "print(cv_X_array.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15806, 3734) (15806,)\n",
      "(6774, 3734) (6774,)\n"
     ]
    }
   ],
   "source": [
    "#train-test-split dataset\n",
    "cv_X_train, cv_X_test, y_train, y_test = train_test_split(cv_X_array, y, test_size = 0.3)\n",
    "\n",
    "print(cv_X_train.shape, y_train.shape)\n",
    "print(cv_X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.7991269138301911\n",
      "test: 0.7202539120165338\n"
     ]
    }
   ],
   "source": [
    "#1. Logistic regression classifier\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cv_X_train, y_train)\n",
    "print('train:', lr.score(cv_X_train, y_train))\n",
    "\n",
    "print('test:', lr.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a. KNN with k = 1 classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(cv_X_train, y_train)\n",
    "print(knn.score(cv_X_train, y_train))\n",
    "\n",
    "print(knn.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b. KNN with k = [3, 5, 7, 9, 11]\n",
    "k = [3, 5, 7, 9, 11]\n",
    "k_train = []\n",
    "k_test = []\n",
    "for i in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(cv_X_train, y_train)\n",
    "    k_train.append(knn.score(cv_X_train, y_train))\n",
    "    k_test.append(knn.score(cv_X_test, y_test))\n",
    "    \n",
    "    print(k, knn.score(cv_X_train, y_train))\n",
    "    print(k, knn.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.7947614829811463\n",
      "test: 0.6762621789193977\n"
     ]
    }
   ],
   "source": [
    "#3. Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(cv_X_train, y_train)\n",
    "print('train:', rf.score(cv_X_train, y_train))\n",
    "\n",
    "print('test:', rf.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding in new variables for thread title\n",
    "    #1. binary variable if 'cat' or 'funny' appears in title\n",
    "    #2. numerical variable for length of title: number of words\n",
    "    #3. numerical variable for intensity of title: punctuation - ?s and !s\n",
    "    #4. additional step: creating dictionary of words for classifying positive/negative sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22273\n",
       "1      307\n",
       "Name: binary_variable, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. binary variable if 'cat' or 'funny' appears in title\n",
    "import numpy as np\n",
    "binary_variable = [1 if ('cat' in i) or ('funny' in i) else 0 for i in data['title']]\n",
    "binary_variable = pd.Series(binary_variable)\n",
    "\n",
    "data['binary_variable'] = binary_variable\n",
    "data['binary_variable'].value_counts()\n",
    "\n",
    "#i = data['title'][0]\n",
    "#for i in data['title']:\n",
    "#    if ('cat' or 'funny') in i:\n",
    "#        print (i, True)\n",
    "        \n",
    "#returns df rows for condition: np.where(data['title'].str.contains('cat'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for 'cat' and 'funny'\n",
    "\n",
    "#X['cat_variable'] = data['title'].str.contains('cat')\n",
    "#X['funny_variable'] = data['title'].str.contains('funny')\n",
    "\n",
    "#print(X['cat_variable'].value_counts())\n",
    "#print ('\\n')\n",
    "#print(X['funny_variable'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22580, 3734)\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer with binary_variable\n",
    "X = data['subreddit']\n",
    "\n",
    "cv = CountVectorizer(stop_words = 'english')\n",
    "cv.fit(X)\n",
    "cv_X = cv.fit_transform(X)\n",
    "cv_X_array = cv_X.toarray()\n",
    "\n",
    "print(cv_X_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22580, 3735)\n"
     ]
    }
   ],
   "source": [
    "cv_X = pd.DataFrame(cv_X_array)\n",
    "cv_X['binary_variable'] = data['binary_variable']\n",
    "print(cv_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15806, 3735) (15806,)\n",
      "(6774, 3735) (6774,)\n"
     ]
    }
   ],
   "source": [
    "#train-test-split dataset\n",
    "cv_X_train, cv_X_test, y_train, y_test = train_test_split(cv_X, y, test_size = 0.3)\n",
    "\n",
    "print(cv_X_train.shape, y_train.shape)\n",
    "print(cv_X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.791155257497153\n",
      "test: 0.672128727487452\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier with binary_variable\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(cv_X_train, y_train)\n",
    "print('train:', rf.score(cv_X_train, y_train))\n",
    "\n",
    "print('test:', rf.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary variable did not improve model...decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2020\n",
       "4    1986\n",
       "3    1924\n",
       "6    1824\n",
       "7    1693\n",
       "Name: num_variable, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. numerical variable for length of title: number of words\n",
    "    #additional step: categorize into bins\n",
    "\n",
    "data['num_variable'] = [len(i.split()) for i in data['title']]\n",
    "data['num_variable'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     18835\n",
       "1      3153\n",
       "2       378\n",
       "3       138\n",
       "4        42\n",
       "5        15\n",
       "6        10\n",
       "7         3\n",
       "9         2\n",
       "8         2\n",
       "10        1\n",
       "20        1\n",
       "Name: intensity_variable, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. numerical variable for intensity of title: punctuation - ?s and !s\n",
    "data['intensity_variable'] = [(i.count('!') + i.count('?')) for i in data['title']]\n",
    "data['intensity_variable'].value_counts()\n",
    "\n",
    "#for i in data['title']:\n",
    "#    print(i.count('!') + i.count('?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22580, 3737)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3727</th>\n",
       "      <th>3728</th>\n",
       "      <th>3729</th>\n",
       "      <th>3730</th>\n",
       "      <th>3731</th>\n",
       "      <th>3732</th>\n",
       "      <th>3733</th>\n",
       "      <th>binary_variable</th>\n",
       "      <th>num_variable</th>\n",
       "      <th>intensity_variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9         ...          3727  3728  3729  3730  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0         ...             0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0         ...             0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0         ...             0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0         ...             0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0         ...             0     0     0     0   \n",
       "\n",
       "   3731  3732  3733  binary_variable  num_variable  intensity_variable  \n",
       "0     0     0     0                0            39                   0  \n",
       "1     0     0     0                0            18                   0  \n",
       "2     0     0     0                0            23                   0  \n",
       "3     0     0     0                0             4                   0  \n",
       "4     0     0     0                0            21                   0  \n",
       "\n",
       "[5 rows x 3737 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_X['num_variable'] = data['num_variable']\n",
    "cv_X['intensity_variable'] = data['intensity_variable']\n",
    "\n",
    "print(cv_X.shape)\n",
    "cv_X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15806, 3737) (15806,)\n",
      "(6774, 3737) (6774,)\n"
     ]
    }
   ],
   "source": [
    "#train-test-split dataset\n",
    "cv_X_train, cv_X_test, y_train, y_test = train_test_split(cv_X, y, test_size = 0.3)\n",
    "\n",
    "print(cv_X_train.shape, y_train.shape)\n",
    "print(cv_X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9211691762621789\n",
      "test: 0.6182462356067316\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier with new features\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(cv_X_train, y_train)\n",
    "print('train:', rf.score(cv_X_train, y_train))\n",
    "\n",
    "print('test:', rf.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding in num_variable and intensity_variable increased the training model score\n",
    "    #decreased test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using CountVectorizer to create features based on thread title\n",
    "cv2 = CountVectorizer()\n",
    "cv2.fit(data['title'])\n",
    "cv2_X = cv2.fit_transform(data['title'])\n",
    "cv2_X_array = cv2_X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_X = pd.DataFrame(cv2_X_array)\n",
    "\n",
    "cv_X_all = pd.concat([cv_X, cv2_X], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22580, 3737) (22580, 26050) (22580, 29787)\n"
     ]
    }
   ],
   "source": [
    "print(cv_X.shape, cv2_X.shape, cv_X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15806, 29787) (15806,)\n",
      "(6774, 29787) (6774,)\n"
     ]
    }
   ],
   "source": [
    "#train-test-split dataset\n",
    "cv_X_all_train, cv_X_all_test, y_train, y_test = train_test_split(cv_X_all, y, test_size = 0.3)\n",
    "\n",
    "print(cv_X_all_train.shape, y_train.shape)\n",
    "print(cv_X_all_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.8787802100468176\n",
      "test: 0.5079716563330381\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier with new features\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(cv_X_train, y_train)\n",
    "print('train:', rf.score(cv_X_train, y_train))\n",
    "\n",
    "print('test:', rf.score(cv_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding CountVectorizer of post title leads to better model score for training data\n",
    "    #decreased test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63662239 0.63472486 0.63714015 0.62828219 0.625     ] [0.60029499 0.60738007 0.59852399 0.605613   0.57976366]\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation to evaluate above model\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_scores = cross_val_score(rf, cv_X_all_train, y_train, cv = 5)\n",
    "test_scores = cross_val_score(rf, cv_X_all_test, y_test, cv = 5)\n",
    "print(train_scores, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation scores show poor performance of Random Forest model with CountVectorized subreddit and title variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Treebased Models\n",
    "    #1. Logistic Regression\n",
    "    #2. KNN\n",
    "        #a. with k = 1\n",
    "        #b. with k = [3, 5, 7, 9, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9305327090978109\n",
      "0.6891054030115146\n"
     ]
    }
   ],
   "source": [
    "#1. Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cv_X_all_train, y_train)\n",
    "print(lr.score(cv_X_all_train, y_train))\n",
    "\n",
    "print(lr.score(cv_X_all_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression shows similarly poor performance to RF model\n",
    "    #high bias: underfit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9843730229026951\n",
      "0.5481251845290818\n"
     ]
    }
   ],
   "source": [
    "#2a. KNN with k = 1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(cv_X_all_train, y_train)\n",
    "print(knn.score(cv_X_all_train, y_train))\n",
    "\n",
    "print(knn.score(cv_X_all_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with k = 1 shows high bias: training set scores higher than RandomForest model\n",
    "    #decreased test set performance (worst of 3 models); KNN best fits non-linear relationships\n",
    "    #test with different k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b. KNN with k = [3, 5, 7, 9, 11]\n",
    "k = [3, 5, 7, 9, 11]\n",
    "k_train = []\n",
    "k_test = []\n",
    "for i in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(cv_X_all_train, y_train)\n",
    "    k_train.append(knn.score(cv_X_all_train, y_train))\n",
    "    k_test.append(knn.score(cv_X_all_test, y_test))\n",
    "    \n",
    "    print(k, knn.score(cv_X_all_train, y_train))\n",
    "    print(k, knn.score(cv_X_all_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with k = [3, 5, 7, 9, 11] shows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
