{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets from API call\n",
    "done = pd.read_json('alex_datasets/done_2018_05_26__04_03_28.json')\n",
    "dtwo = pd.read_json('alex_datasets/dtwo_2018_05_26__08_03_27.json')\n",
    "dthree = pd.read_json('alex_datasets/dthree_2018_05_26__12_03_28.json')\n",
    "dfour = pd.read_json('alex_datasets/dfour_2018_05_26__16_03_32.json')\n",
    "dfive = pd.read_json('alex_datasets/dfive_2018_05_26__20_03_30.json')\n",
    "dsix = pd.read_json('alex_datasets/dsix_2018_05_27__00_03_29.json')\n",
    "\n",
    "done = pd.DataFrame(done)\n",
    "dtwo = pd.DataFrame(dtwo)\n",
    "dthree = pd.DataFrame(dthree)\n",
    "dfour = pd.DataFrame(dfour)\n",
    "dfive = pd.DataFrame(dfive)\n",
    "dsix = pd.DataFrame(dsix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "posts: (2500, 85)\n",
      "unique posts: (2402, 1) \n",
      "\n",
      "dtwo\n",
      "posts: (2500, 84)\n",
      "unique posts: (2433, 1) \n",
      "\n",
      "dthree\n",
      "posts: (2500, 84)\n",
      "unique posts: (2374, 1) \n",
      "\n",
      "dfour\n",
      "posts: (2500, 85)\n",
      "unique posts: (2323, 1) \n",
      "\n",
      "dfive\n",
      "posts: (2500, 84)\n",
      "unique posts: (2389, 1) \n",
      "\n",
      "dsix\n",
      "posts: (2500, 84)\n",
      "unique posts: (2390, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for dupes in datasets\\\n",
    "print('done')\n",
    "print('posts:', done.shape)\n",
    "print('unique posts:', pd.DataFrame(done['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dtwo')\n",
    "print('posts:', dtwo.shape)\n",
    "print('unique posts:', pd.DataFrame(dtwo['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dthree')\n",
    "print('posts:', dthree.shape)\n",
    "print('unique posts:', pd.DataFrame(dthree['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dfour')\n",
    "print('posts:', dfour.shape)\n",
    "print('unique posts:', pd.DataFrame(dfour['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dfive')\n",
    "print('posts:', dfive.shape)\n",
    "print('unique posts:', pd.DataFrame(dfive['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dsix')\n",
    "print('posts:', dsix.shape)\n",
    "print('unique posts:', pd.DataFrame(dsix['title'].value_counts()).shape, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6833, 85)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregating datasets\n",
    "data1 = pd.concat([done, dtwo, dthree, dfour, dfive, dsix], ignore_index = True)\n",
    "data1.drop_duplicates(subset = 'title', inplace = True)\n",
    "\n",
    "data1.shape    #aside from dupes within each dataset, there are additional duples across datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dninteen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-3eab3ebdd58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mdseventeen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdseventeen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdeighteen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeighteen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdnineteen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdninteen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mdtwenty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtwenty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdtwentyone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtwentyone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dninteen' is not defined"
     ]
    }
   ],
   "source": [
    "#adding more posts\n",
    "dseven = pd.read_json('alex_datasets/dseven_2018_05_27__04_03_25.json')\n",
    "deight = pd.read_json('alex_datasets/deight_2018_05_27__08_03_25.json')\n",
    "dnine = pd.read_json('alex_datasets/dnine_2018_05_27__12_03_30.json')\n",
    "dten = pd.read_json('alex_datasets/dten_2018_05_27__16_03_31.json')\n",
    "deleven = pd.read_json('alex_datasets/deleven_2018_05_27__20_03_32.json')\n",
    "dtwelve = pd.read_json('alex_datasets/dtwelve_2018_05_28__00_03_27.json')\n",
    "dthirteen = pd.read_json('alex_datasets/dthirteen_2018_05_28__04_03_30.json')\n",
    "dfourteen = pd.read_json('alex_datasets/dfourteen_2018_05_28__08_03_26.json')\n",
    "dfifteen = pd.read_json('alex_datasets/dfifteen_2018_05_28__12_03_28.json')\n",
    "dsixteen = pd.read_json('alex_datasets/dsixteen_2018_05_28__16_03_32.json')\n",
    "dseventeen = pd.read_json('alex_datasets/dseventeen_2018_05_28__20_03_33.json')\n",
    "deighteen = pd.read_json('alex_datasets/deighteen_2018_05_29__00_03_27.json')\n",
    "dnineteen = pd.read_json('alex_datasets/dnineteen_2018_05_29__04_03_26.json')\n",
    "dtwenty = pd.read_json('alex_datasets/dtwenty_2018_05_29__08_03_26.json')\n",
    "dtwentyone = pd.read_json('alex_datasets/dtwentyone_2018_05_29__12_03_32.json')\n",
    "dtwentytwo = pd.read_json('alex_datasets/dtwentytwo_2018_05_29__16_03_28.json')\n",
    "\n",
    "dseven = pd.DataFrame(dseven)\n",
    "deight = pd.DataFrame(deight)\n",
    "dnine = pd.DataFrame(dnine)\n",
    "dten = pd.DataFrame(dten)\n",
    "deleven = pd.DataFrame(deleven)\n",
    "dtwelve = pd.DataFrame(dtwelve)\n",
    "dthirteen = pd.DataFrame(dthirteen)\n",
    "dfourteen = pd.DataFrame(dfourteen)\n",
    "dfifteen = pd.DataFrame(dfifteen)\n",
    "dsixteen = pd.DataFrame(dsixteen)\n",
    "dseventeen = pd.DataFrame(dseventeen)\n",
    "deighteen = pd.DataFrame(deighteen)\n",
    "dnineteen = pd.DataFrame(dninteen)\n",
    "dtwenty = pd.DataFrame(dtwenty)\n",
    "dtwentyone = pd.DataFrame(dtwentyone)\n",
    "dtwentytwo = pd.DataFrame(dtwentytwo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dseven\n",
      "posts: (2500, 84)\n",
      "unique posts: (2426, 1) \n",
      "\n",
      "deight\n",
      "posts: (2500, 84)\n",
      "unique posts: (2401, 1) \n",
      "\n",
      "dnine\n",
      "posts: (2500, 84)\n",
      "unique posts: (2392, 1) \n",
      "\n",
      "dten\n",
      "posts: (2500, 84)\n",
      "unique posts: (2283, 1) \n",
      "\n",
      "deleven\n",
      "posts: (2500, 85)\n",
      "unique posts: (2396, 1) \n",
      "\n",
      "dtwelve\n",
      "posts: (2500, 85)\n",
      "unique posts: (2353, 1) \n",
      "\n",
      "dthirteen\n",
      "posts: (2500, 84)\n",
      "unique posts: (2334, 1) \n",
      "\n",
      "dfourteen\n",
      "posts: (2500, 84)\n",
      "unique posts: (2427, 1) \n",
      "\n",
      "dfifteen\n",
      "posts: (2500, 84)\n",
      "unique posts: (2193, 1) \n",
      "\n",
      "dsixteen\n",
      "posts: (2500, 84)\n",
      "unique posts: (2284, 1) \n",
      "\n",
      "dseventeen\n",
      "posts: (2500, 84)\n",
      "unique posts: (2332, 1) \n",
      "\n",
      "deighteen\n",
      "posts: (2500, 85)\n",
      "unique posts: (2349, 1) \n",
      "\n",
      "dnineteen\n",
      "posts: (2500, 85)\n",
      "unique posts: (2069, 1) \n",
      "\n",
      "dtwenty\n",
      "posts: (2500, 84)\n",
      "unique posts: (2396, 1) \n",
      "\n",
      "dtwentyone\n",
      "posts: (2500, 84)\n",
      "unique posts: (2364, 1) \n",
      "\n",
      "dtwentytwo\n",
      "posts: (2500, 84)\n",
      "unique posts: (2360, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('dseven')\n",
    "print('posts:', dseven.shape)\n",
    "print('unique posts:', pd.DataFrame(dseven['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('deight')\n",
    "print('posts:', deight.shape)\n",
    "print('unique posts:', pd.DataFrame(deight['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dnine')\n",
    "print('posts:', dnine.shape)\n",
    "print('unique posts:', pd.DataFrame(dnine['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dten')\n",
    "print('posts:', dten.shape)\n",
    "print('unique posts:', pd.DataFrame(dten['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('deleven')\n",
    "print('posts:', deleven.shape)\n",
    "print('unique posts:', pd.DataFrame(deleven['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dtwelve')\n",
    "print('posts:', dtwelve.shape)\n",
    "print('unique posts:', pd.DataFrame(dtwelve['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dthirteen')\n",
    "print('posts:', dthirteen.shape)\n",
    "print('unique posts:', pd.DataFrame(dthirteen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dfourteen')\n",
    "print('posts:', dfourteen.shape)\n",
    "print('unique posts:', pd.DataFrame(dfourteen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dfifteen')\n",
    "print('posts:', dfifteen.shape)\n",
    "print('unique posts:', pd.DataFrame(dfifteen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dsixteen')\n",
    "print('posts:', dsixteen.shape)\n",
    "print('unique posts:', pd.DataFrame(dsixteen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dseventeen')\n",
    "print('posts:', dseventeen.shape)\n",
    "print('unique posts:', pd.DataFrame(dseventeen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('deighteen')\n",
    "print('posts:', deighteen.shape)\n",
    "print('unique posts:', pd.DataFrame(deighteen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dnineteen')\n",
    "print('posts:', dnineteen.shape)\n",
    "print('unique posts:', pd.DataFrame(dnineteen['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dtwenty')\n",
    "print('posts:', dtwenty.shape)\n",
    "print('unique posts:', pd.DataFrame(dtwenty['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dtwentyone')\n",
    "print('posts:', dtwentyone.shape)\n",
    "print('unique posts:', pd.DataFrame(dtwentyone['title'].value_counts()).shape, '\\n')\n",
    "\n",
    "print('dtwentytwo')\n",
    "print('posts:', dtwentytwo.shape)\n",
    "print('unique posts:', pd.DataFrame(dtwentytwo['title'].value_counts()).shape, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q: how to add in all jsons from folder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15747, 85)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregating datasets\n",
    "data2 = pd.concat([dseven, deight, dnine, dten, deleven, dtwelve, \n",
    "                   dthirteen, dfourteen, dfifteen,\n",
    "                   dsixteen, dseventeen, deighteen, dnineteen, dtwenty,\n",
    "                  dtwentyone, dtwentytwo],\n",
    "                  ignore_index = True)\n",
    "data2.drop_duplicates(subset = 'title', inplace = True)\n",
    "\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22580, 85)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data1, data2], ignore_index = True)\n",
    "data.drop_duplicates(subset = 'title')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results to csv\n",
    "data.to_csv('data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
